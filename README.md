# llama-cpp-python-wheels
Pre-built wheels for llama-cpp-python across platforms and CUDA versions.

## Available Wheels

### CUDA 13.0 - Latest
| File | OS | Python | Driver | GPU Support | Size |
|------|-----|--------|--------|-------------|------|
| [llama_cpp_python-0.3.16+cuda13.0.sm86.ampere-cp313-cp313-win_amd64.whl](https://github.com/dougeeai/llama-cpp-python-wheels/releases/download/v0.3.16-cuda13.0-sm86-py313/llama_cpp_python-0.3.16+cuda13.0.sm86.ampere-cp313-cp313-win_amd64.whl) | Windows 10/11 | 3.13 | 580+ | RTX 30 series (Ampere, sm_86) | 61.4 MB |
| [llama_cpp_python-0.3.16+cuda13.0.sm86.ampere-cp312-cp312-win_amd64.whl](https://github.com/dougeeai/llama-cpp-python-wheels/releases/download/v0.3.16-cuda13.0-sm86-py312/llama_cpp_python-0.3.16+cuda13.0.sm86.ampere-cp312-cp312-win_amd64.whl) | Windows 10/11 | 3.12 | 580+ | RTX 30 series (Ampere, sm_86) | 61.4 MB |
| [llama_cpp_python-0.3.16+cuda13.0.sm86.ampere-cp311-cp311-win_amd64.whl](https://github.com/dougeeai/llama-cpp-python-wheels/releases/download/v0.3.16-cuda13.0-sm86-py311/llama_cpp_python-0.3.16+cuda13.0.sm86.ampere-cp311-cp311-win_amd64.whl) | Windows 10/11 | 3.11 | 580+ | RTX 30 series (Ampere, sm_86) | 61.4 MB |
| [llama_cpp_python-0.3.16+cuda13.0.sm86.ampere-cp310-cp310-win_amd64.whl](https://github.com/dougeeai/llama-cpp-python-wheels/releases/download/v0.3.16-cuda13.0-sm86-py310/llama_cpp_python-0.3.16+cuda13.0.sm86.ampere-cp310-cp310-win_amd64.whl) | Windows 10/11 | 3.10 | 580+ | RTX 30 series (Ampere, sm_86) | 61.4 MB |
| [llama_cpp_python-0.3.16+cuda13.0.sm89.ada-cp313-cp313-win_amd64.whl](https://github.com/dougeeai/llama-cpp-python-wheels/releases/download/v0.3.16-cuda13.0-sm89-py313/llama_cpp_python-0.3.16+cuda13.0.sm89.ada-cp313-cp313-win_amd64.whl) | Windows 10/11 | 3.13 | 580+ | RTX 40 series/Ada Pro (sm_89) | 61.4 MB |
| [llama_cpp_python-0.3.16+cuda13.0.sm89.ada-cp312-cp312-win_amd64.whl](https://github.com/dougeeai/llama-cpp-python-wheels/releases/download/v0.3.16-cuda13.0-sm89-py312/llama_cpp_python-0.3.16+cuda13.0.sm89.ada-cp312-cp312-win_amd64.whl) | Windows 10/11 | 3.12 | 580+ | RTX 40 series/Ada Pro (sm_89) | 61.4 MB |
| [llama_cpp_python-0.3.16+cuda13.0.sm89.ada-cp311-cp311-win_amd64.whl](https://github.com/dougeeai/llama-cpp-python-wheels/releases/download/v0.3.16-cuda13.0-sm89-py311/llama_cpp_python-0.3.16+cuda13.0.sm89.ada-cp311-cp311-win_amd64.whl) | Windows 10/11 | 3.11 | 580+ | RTX 40 series/Ada Pro (sm_89) | 61.4 MB |
| [llama_cpp_python-0.3.16+cuda13.0.sm89.ada-cp310-cp310-win_amd64.whl](https://github.com/dougeeai/llama-cpp-python-wheels/releases/download/v0.3.16-cuda13.0-sm89-py310/llama_cpp_python-0.3.16+cuda13.0.sm89.ada-cp310-cp310-win_amd64.whl) | Windows 10/11 | 3.10 | 580+ | RTX 40 series/Ada Pro (sm_89) | 61.3 MB |

### CUDA 12.1 - Recommended
| File | OS | Python | Driver | GPU Support | Size |
|------|-----|--------|--------|-------------|------|
| [llama_cpp_python-0.3.16+cuda12.1.sm86.ampere-cp313-cp313-win_amd64.whl](https://github.com/dougeeai/llama-cpp-python-wheels/releases/download/v0.3.16-cuda12.1-sm86-py313/llama_cpp_python-0.3.16+cuda12.1.sm86.ampere-cp313-cp313-win_amd64.whl) | Windows 10/11 | 3.13 | 525.60.13+ | RTX 30 series (Ampere, sm_86) | 92.2 MB |
| [llama_cpp_python-0.3.16+cuda12.1.sm86.ampere-cp312-cp312-win_amd64.whl](https://github.com/dougeeai/llama-cpp-python-wheels/releases/download/v0.3.16-cuda12.1-sm86-py312/llama_cpp_python-0.3.16+cuda12.1.sm86.ampere-cp312-cp312-win_amd64.whl) | Windows 10/11 | 3.12 | 525.60.13+ | RTX 30 series (Ampere, sm_86) | 61.4 MB |
| [llama_cpp_python-0.3.16+cuda12.1.sm86.ampere-cp311-cp311-win_amd64.whl](https://github.com/dougeeai/llama-cpp-python-wheels/releases/download/v0.3.16-cuda12.1-sm86-py311/llama_cpp_python-0.3.16+cuda12.1.sm86.ampere-cp311-cp311-win_amd64.whl) | Windows 10/11 | 3.11 | 525.60.13+ | RTX 30 series (Ampere, sm_86) | 61.4 MB |
| [llama_cpp_python-0.3.16+cuda12.1.sm86.ampere-cp310-cp310-win_amd64.whl](https://github.com/dougeeai/llama-cpp-python-wheels/releases/download/v0.3.16-cuda12.1-sm86-py310/llama_cpp_python-0.3.16+cuda12.1.sm86.ampere-cp310-cp310-win_amd64.whl) | Windows 10/11 | 3.10 | 525.60.13+ | RTX 30 series (Ampere, sm_86) | 61.4 MB |
| [llama_cpp_python-0.3.16+cuda12.1.sm89.ada-cp313-cp313-win_amd64.whl](https://github.com/dougeeai/llama-cpp-python-wheels/releases/download/v0.3.16-cuda12.1-sm89-py313/llama_cpp_python-0.3.16+cuda12.1.sm89.ada-cp313-cp313-win_amd64.whl) | Windows 10/11 | 3.13 | 525.60.13+ | RTX 40 series/Ada Pro (sm_89) | 100.6 MB |
| [llama_cpp_python-0.3.16+cuda12.1.sm89.ada-cp312-cp312-win_amd64.whl](https://github.com/dougeeai/llama-cpp-python-wheels/releases/download/v0.3.16-cuda12.1-sm89-py312/llama_cpp_python-0.3.16+cuda12.1.sm89.ada-cp312-cp312-win_amd64.whl) | Windows 10/11 | 3.12 | 525.60.13+ | RTX 40 series/Ada Pro (sm_89) | 100.6 MB |
| [llama_cpp_python-0.3.16+cuda12.1.sm89.ada-cp311-cp311-win_amd64.whl](https://github.com/dougeeai/llama-cpp-python-wheels/releases/download/v0.3.16-cuda12.1-sm89-py311/llama_cpp_python-0.3.16+cuda12.1.sm89.ada-cp311-cp311-win_amd64.whl) | Windows 10/11 | 3.11 | 525.60.13+ | RTX 40 series/Ada Pro (sm_89) | 100.6 MB |
| [llama_cpp_python-0.3.16+cuda12.1.sm89.ada-cp310-cp310-win_amd64.whl](https://github.com/dougeeai/llama-cpp-python-wheels/releases/download/v0.3.16-cuda12.1-sm89-py310/llama_cpp_python-0.3.16+cuda12.1.sm89.ada-cp310-cp310-win_amd64.whl) | Windows 10/11 | 3.10 | 525.60.13+ | RTX 40 series/Ada Pro (sm_89) | 100.6 MB |

### CUDA 11.8 - Most Compatible
| File | OS | Python | Driver | GPU Support | Size |
|------|-----|--------|--------|-------------|------|
| [llama_cpp_python-0.3.16+cuda11.8.sm86.ampere-cp313-cp313-win_amd64.whl](https://github.com/dougeeai/llama-cpp-python-wheels/releases/download/v0.3.16-cuda11.8-sm86-py313/llama_cpp_python-0.3.16+cuda11.8.sm86.ampere-cp313-cp313-win_amd64.whl) | Windows 10/11 | 3.13 | 450.80.02+ | RTX 30 series (Ampere, sm_86) | 100.6 MB |
| [llama_cpp_python-0.3.16+cuda11.8.sm86.ampere-cp312-cp312-win_amd64.whl](https://github.com/dougeeai/llama-cpp-python-wheels/releases/download/v0.3.16-cuda11.8-sm86-py312/llama_cpp_python-0.3.16+cuda11.8.sm86.ampere-cp312-cp312-win_amd64.whl) | Windows 10/11 | 3.12 | 450.80.02+ | RTX 30 series (Ampere, sm_86) | 100.6 MB |
| [llama_cpp_python-0.3.16+cuda11.8.sm86.ampere-cp311-cp311-win_amd64.whl](https://github.com/dougeeai/llama-cpp-python-wheels/releases/download/v0.3.16-cuda11.8-sm86-py311/llama_cpp_python-0.3.16+cuda11.8.sm86.ampere-cp311-cp311-win_amd64.whl) | Windows 10/11 | 3.11 | 450.80.02+ | RTX 30 series (Ampere, sm_86) | 100.6 MB |
| [llama_cpp_python-0.3.16+cuda11.8.sm86.ampere-cp310-cp310-win_amd64.whl](https://github.com/dougeeai/llama-cpp-python-wheels/releases/download/v0.3.16-cuda11.8-sm86-py310/llama_cpp_python-0.3.16+cuda11.8.sm86.ampere-cp310-cp310-win_amd64.whl) | Windows 10/11 | 3.10 | 450.80.02+ | RTX 30 series (Ampere, sm_86) | 100.6 MB |
| [llama_cpp_python-0.3.16+cuda11.8.sm89.ada-cp313-cp313-win_amd64.whl](https://github.com/dougeeai/llama-cpp-python-wheels/releases/download/v0.3.16-cuda11.8-sm89-py313/llama_cpp_python-0.3.16+cuda11.8.sm89.ada-cp313-cp313-win_amd64.whl) | Windows 10/11 | 3.13 | 450.80.02+ | RTX 40 series/Ada Pro (sm_89) | 100.5 MB |
| [llama_cpp_python-0.3.16+cuda11.8.sm89.ada-cp312-cp312-win_amd64.whl](https://github.com/dougeeai/llama-cpp-python-wheels/releases/download/v0.3.16-cuda11.8-sm89-py312/llama_cpp_python-0.3.16+cuda11.8.sm89.ada-cp312-cp312-win_amd64.whl) | Windows 10/11 | 3.12 | 450.80.02+ | RTX 40 series/Ada Pro (sm_89) | 100.5 MB |
| [llama_cpp_python-0.3.16+cuda11.8.sm89.ada-cp311-cp311-win_amd64.whl](https://github.com/dougeeai/llama-cpp-python-wheels/releases/download/v0.3.16-cuda11.8-sm89-py311/llama_cpp_python-0.3.16+cuda11.8.sm89.ada-cp311-cp311-win_amd64.whl) | Windows 10/11 | 3.11 | 450.80.02+ | RTX 40 series/Ada Pro (sm_89) | 100.5 MB |
| [llama_cpp_python-0.3.16+cuda11.8.sm89.ada-cp310-cp310-win_amd64.whl](https://github.com/dougeeai/llama-cpp-python-wheels/releases/download/v0.3.16-cuda11.8-sm89-py310/llama_cpp_python-0.3.16+cuda11.8.sm89.ada-cp310-cp310-win_amd64.whl) | Windows 10/11 | 3.10 | 450.80.02+ | RTX 40 series/Ada Pro (sm_89) | 100.5 MB |

## GPU Support
- **Ampere (sm_86)**: RTX 3060, 3060 Ti, 3070, 3070 Ti, 3080, 3080 Ti, 3090, 3090 Ti
- **Ada Lovelace (sm_89)**: RTX 4060, 4060 Ti, 4070, 4070 Ti, 4070 Ti Super, 4080, 4080 Super, 4090, RTX A6000 Ada, RTX 6000 Ada, RTX 5000 Ada, L40, L40S

## Installation
Download the appropriate wheel from [Releases](../../releases) and install:
```bash
pip install llama_cpp_python-[version]+cuda[cuda_version].sm[arch].[gpu]-cp[python]-cp[python]-win_amd64.whl
```

## Verification
```python
from llama_cpp import Llama
print("llama-cpp-python with CUDA support installed successfully")
```

## Build Notes
Built with:
- Visual Studio 2019/2022 Build Tools
- CUDA Toolkit 11.8, 12.1, 13.0
- CMAKE_CUDA_ARCHITECTURES=86 (Ampere) or 89 (Ada)
- 12+ hour marathon debugging session ðŸ˜…

## License
MIT

Wheels are built from [llama-cpp-python](https://github.com/abetlen/llama-cpp-python) (MIT License)

## Contributing
**Need a different configuration?**
Open an [issue](https://github.com/dougeeai/llama-cpp-python-wheels/issues) with:
- OS (Windows/Linux/macOS)
- Python version
- CUDA version (if applicable)
- GPU model

I'll try to build it if I have access to similar hardware.

## Contact
Questions or issues? Open a [GitHub issue](https://github.com/dougeeai/llama-cpp-python-wheels/issues).
